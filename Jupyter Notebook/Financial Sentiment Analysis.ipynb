{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea978fab-dcf7-42b4-bf18-5e18aa9b4f5f",
   "metadata": {},
   "source": [
    "<h1> Financial Sentiment Analysis </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "4153e38a-9f26-4e6e-a480-330f21f3f53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "09a172fc-f5c1-42b1-b7c4-fea57efc5eb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The GeoSolutions technology will leverage Bene...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>$ESI on lows, down $1.50 to $2.50 BK a real po...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>For the last quarter of 2010 , Componenta 's n...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>According to the Finnish-Russian Chamber of Co...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Swedish buyout firm has sold its remaining...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Sentence Sentiment\n",
       "0  The GeoSolutions technology will leverage Bene...  positive\n",
       "1  $ESI on lows, down $1.50 to $2.50 BK a real po...  negative\n",
       "2  For the last quarter of 2010 , Componenta 's n...  positive\n",
       "3  According to the Finnish-Russian Chamber of Co...   neutral\n",
       "4  The Swedish buyout firm has sold its remaining...   neutral"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"D:\\\\Datasets\\\\financial.csv\", encoding = 'latin1')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "3409a1c5-5792-4e79-a6cb-cf6105c65a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#I will be assigning values for easy coding\n",
    "X = df[\"Sentence\"]\n",
    "y = df[\"Sentiment\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e04870b-cbfc-42d2-812b-b2e01196868c",
   "metadata": {},
   "source": [
    "<h2> Preprocessing </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c62fccc-a4c8-4e6f-bdea-a050bf0fbb76",
   "metadata": {},
   "source": [
    "<h3> Label Encoding </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "2b753097-d369-4502-b82c-e0ce19873c98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['positive' 'negative' 'neutral']\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "#I want to know first the kinds of sentiments in the target, and how many are there\n",
    "print(y.unique())\n",
    "print(y.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "7ad13fea-3ab2-4796-ae31-ae3c7d46ef12",
   "metadata": {},
   "outputs": [],
   "source": [
    "#I will be doing manual label encoding in target variable\n",
    "target = {\n",
    "    'positive' : 0,\n",
    "    'negative' : 1,\n",
    "    'neutral': 2,\n",
    "}\n",
    "\n",
    "y_encoded = y.map(target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5af1ccc-8c6d-4bce-9e09-c5c65781145d",
   "metadata": {},
   "source": [
    "<h3> Removing Special Characters</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "a92a76d8-a20c-463d-8441-f2f0a24653a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Carriage returns:False\n",
      "Newlines: False\n",
      "special char: True\n",
      "$: True\n"
     ]
    }
   ],
   "source": [
    "#Check first if there are newline, carriage returns or special characters\n",
    "carriage_rets = X.str.contains(r'\\r', na = False).any()\n",
    "newline = X.str.contains(r'\\n', na = False).any()\n",
    "special_char = X.str.contains(r'[^\\w\\s]', na = False).any()\n",
    "special_char1 = X.str.contains(r'\\$', na = False).any()\n",
    "\n",
    "print(f\"Carriage returns:{carriage_rets}\")\n",
    "print(f\"Newlines: {newline}\")\n",
    "print(f\"special char: {special_char}\")\n",
    "print(f\"$: {special_char1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "1e4d16ab-9f45-40e6-8f82-0cd4e95e4508",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean the data\n",
    "X_cleaned = X.str.replace(r'[\\r\\n]', ' ', regex=True)  # Replace newlines and carriage returns with space\n",
    "X_cleaned = X_cleaned.str.replace(r'[^\\w\\s]', '', regex=True)  # Remove special characters\n",
    "X_cleaned = X_cleaned.str.replace(r'\\$', '', regex=True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "4e8bc578-09b4-423a-bea9-fe87393568b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Carriage returns:False\n",
      "Newlines: False\n",
      "special char: False\n",
      "$: False\n"
     ]
    }
   ],
   "source": [
    "# recheck\n",
    "carriage_rets = X_cleaned.str.contains(r'\\r', na=False).any()\n",
    "newline = X_cleaned.str.contains(r'\\n', na = False).any()\n",
    "special_char = X_cleaned.str.contains(r'[^\\w\\s]', na = False).any()\n",
    "special_char1 = X_cleaned.str.contains(r'\\$', na = False).any()\n",
    "\n",
    "print(f\"Carriage returns:{carriage_rets}\")\n",
    "print(f\"Newlines: {newline}\")\n",
    "print(f\"special char: {special_char}\")\n",
    "print(f\"$: {special_char1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1037e68-2d0d-46e5-b82c-3c827482a490",
   "metadata": {},
   "source": [
    "<h3> Stemming </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "4ffebf6e-e081-40b9-889a-eceeefdcecc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\abrah\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#Use nltk library to access Porter Stemmer\n",
    "#I decided not to use stopwords since some words may affect the sentiment result\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "808d2d97-0f7a-47e6-bf72-61b8385e564c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "corpus = []\n",
    "\n",
    "for i in range(len(df)):\n",
    "    text = X_cleaned.iloc[i]\n",
    "    text = text.split()\n",
    "    text = [lemmatizer.lemmatize(word) for word in text if word not in stop_words]\n",
    "    text = ' '.join(text)\n",
    "    corpus.append(text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85fab57f-651b-4da4-a107-675bd565a843",
   "metadata": {},
   "source": [
    "<h3> Vectorization </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "ecb2e2b6-1bd3-4410-9f8b-e2e3e51ab1f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer =  CountVectorizer()\n",
    "X_vectorized  = vectorizer.fit_transform(corpus).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d5fb39-cf6a-4a51-b3e4-b68f9b261b35",
   "metadata": {},
   "source": [
    "<h2> Split Data </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "557317de-6405-408c-acdb-15126cdc3d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_vectorized, y_encoded, test_size = 0.2, random_state =42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52d609f9-27fd-422c-ac47-838ea5416cf1",
   "metadata": {},
   "source": [
    "<h2> Build Model </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81aedffd-24cd-4e49-a879-2d4581227695",
   "metadata": {},
   "source": [
    "<h3> Naive Bayes </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "529f1149-dcdf-4a99-b6b9-998ca8122772",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "nb_model = MultinomialNB()\n",
    "nb_model = nb_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "fa9a60d6-8ddf-4ca9-882f-9ab4142e7ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_model_pred = nb_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b2bab14-4f98-4a41-a825-d7f33cbd8c05",
   "metadata": {},
   "source": [
    "<h4> Evaluation </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "3aa1262a-d5f4-4894-9d65-bb107b8c7cee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Model Accuracy: 0.6937553464499572\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.67      0.69       372\n",
      "           1       0.40      0.35      0.37       175\n",
      "           2       0.75      0.81      0.78       622\n",
      "\n",
      "    accuracy                           0.69      1169\n",
      "   macro avg       0.62      0.61      0.61      1169\n",
      "weighted avg       0.69      0.69      0.69      1169\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "nb_ac = accuracy_score(y_test, nb_model_pred)\n",
    "nb_cr = classification_report(y_test, nb_model_pred)\n",
    "\n",
    "print(f\"Naive Bayes Model Accuracy: {nb_ac}\")\n",
    "print(nb_cr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab14da5-6bdf-4b56-8bd1-3ec1a18df439",
   "metadata": {},
   "source": [
    "<h3> Logistic Regression </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "3cd700f0-63f0-4ca8-b6d4-af2fa9b65306",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logreg_model = LogisticRegression(multi_class='ovr', max_iter = 1000, solver = 'saga', class_weight = 'balanced')\n",
    "logreg_model = logreg_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "eb57fb01-169d-476a-bfe3-b0adcd4507f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_model_pred = logreg_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f673d556-ce28-4734-a941-47135f186ed7",
   "metadata": {},
   "source": [
    "<h4> Evaluation </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "976613c6-2d8d-4b97-bcfa-400c7d6f09cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 0.6869118905047049\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.73      0.74       372\n",
      "           1       0.36      0.38      0.37       175\n",
      "           2       0.75      0.75      0.75       622\n",
      "\n",
      "    accuracy                           0.69      1169\n",
      "   macro avg       0.62      0.62      0.62      1169\n",
      "weighted avg       0.69      0.69      0.69      1169\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logreg_ac = accuracy_score(y_test, logreg_model_pred)\n",
    "logreg_cr = classification_report(y_test, logreg_model_pred)\n",
    "\n",
    "print(f\"Model Accuracy: {logreg_ac}\")\n",
    "print(logreg_cr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e4932c2-9117-4ad4-99c6-ee7b0cac8427",
   "metadata": {},
   "source": [
    "<h2> XGBoost </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "f260437b-a717-4de1-a149-5d435e55e18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "d6e0a3b7-bebe-4aba-ac78-6d818c6c2434",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = XGBClassifier(objective='multi:softmax', n_estimators = 200 ,num_class=3, random_state=42)\n",
    "xgb_model = xgb_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "198d1ebb-732d-4a90-a42e-1596e23c209b",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model_pred = xgb_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "836aa4de-307f-4814-9f87-a712e6efa22c",
   "metadata": {},
   "source": [
    "<h4> Evaluation </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "ed168db3-eb88-464d-800b-fb1ed98d6f67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Model Accuracy: 0.6843455945252352\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.67      0.71       372\n",
      "           1       0.36      0.21      0.27       175\n",
      "           2       0.70      0.83      0.76       622\n",
      "\n",
      "    accuracy                           0.68      1169\n",
      "   macro avg       0.60      0.57      0.58      1169\n",
      "weighted avg       0.67      0.68      0.67      1169\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xg_ac = accuracy_score(y_test, xgb_model_pred)\n",
    "\n",
    "print(f\"XGBoost Model Accuracy: {xg_ac}\")\n",
    "print(classification_report(y_test, xgb_model_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b136e969-3e9a-4137-a89b-ed0495000e88",
   "metadata": {},
   "source": [
    "<h1> SVC </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "5324665f-5f40-418f-b4de-3a1d3f143803",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "2143cb0d-b8ba-40e5-bb5c-577e30ca925c",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_model = SVC()\n",
    "svc_model = svc_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "677f2034-ac4e-4292-9214-2cbdfba71eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_model_pred = svc_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "5382fd35-4376-40a9-8b4e-441b59a79521",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 0.6826347305389222\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.56      0.65       372\n",
      "           1       0.34      0.07      0.11       175\n",
      "           2       0.67      0.93      0.78       622\n",
      "\n",
      "    accuracy                           0.68      1169\n",
      "   macro avg       0.60      0.52      0.51      1169\n",
      "weighted avg       0.65      0.68      0.64      1169\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svc_ac = accuracy_score(y_test, svc_model_pred)\n",
    "svc_cr = classification_report(y_test, svc_model_pred)\n",
    "\n",
    "print(f\"Model Accuracy: {svc_ac}\")\n",
    "print(svc_cr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "048c70b5-0d4f-4c68-bb67-95dc616ab283",
   "metadata": {},
   "source": [
    "<h1> Prediction of Input Data </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "0b01e549-d499-4b71-9c68-85099ab0747d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Input text here:  increased\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: The sentiment is Positive :)\n"
     ]
    }
   ],
   "source": [
    "input_text = input(\"Input text here: \")\n",
    "\n",
    "input_text = input_text.split()\n",
    "input_text = [lemmatizer.lemmatize(word) for word in input_text]\n",
    "input_text = ' '.join(input_text)\n",
    "\n",
    "input_text = vectorizer.transform([input_text])\n",
    "\n",
    "#-predict---\n",
    "predicted = nb_model.predict(input_text)\n",
    "\n",
    "if predicted == 0:\n",
    "    print(\"Result: The sentiment is Positive :)\")\n",
    "elif predicted == 1:\n",
    "    print(\"Result: The sentiment is Negative :(\")\n",
    "else:\n",
    "    print(\"Result: The sentiment is just Neutral :|\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "a9905886-08f5-4832-805c-e2f472a1192c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Input text here:  increased\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: The sentiment is Positive :)\n"
     ]
    }
   ],
   "source": [
    "input_text = input(\"Input text here: \")\n",
    "\n",
    "input_text = input_text.split()\n",
    "input_text = [lemmatizer.lemmatize(word) for word in input_text]\n",
    "input_text = ' '.join(input_text)\n",
    "\n",
    "input_text = vectorizer.transform([input_text])\n",
    "\n",
    "#-predict---\n",
    "predicted = logreg_model.predict(input_text)\n",
    "\n",
    "if predicted == 0:\n",
    "    print(\"Result: The sentiment is Positive :)\")\n",
    "elif predicted == 1:\n",
    "    print(\"Result: The sentiment is Negative :(\")\n",
    "else:\n",
    "    print(\"Result: The sentiment is just Neutral :|\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "3d8f14f4-53bd-4809-a273-36807f3a3d98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Input text here:  increased\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: The sentiment is Positive :)\n"
     ]
    }
   ],
   "source": [
    "input_text = input(\"Input text here: \")\n",
    "\n",
    "input_text = input_text.split()\n",
    "input_text = [lemmatizer.lemmatize(word) for word in input_text]\n",
    "input_text = ' '.join(input_text)\n",
    "\n",
    "input_text = vectorizer.transform([input_text])\n",
    "\n",
    "#-predict---\n",
    "predicted = xgb_model.predict(input_text)\n",
    "\n",
    "if predicted == 0:\n",
    "    print(\"Result: The sentiment is Positive :)\")\n",
    "elif predicted == 1:\n",
    "    print(\"Result: The sentiment is Negative :(\")\n",
    "else:\n",
    "    print(\"Result: The sentiment is just Neutral :|\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "436a1d92-18a1-45b1-bec8-58b72a6899c6",
   "metadata": {},
   "source": [
    "<h1> Model Local Deployment </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "31848c29-ea8d-4e79-bfdd-ab58b842ff79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "f153860c-e6b6-4c7d-b2bf-0fadc0ee1cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the XGBoost model\n",
    "pickle.dump(nb_model, open('nb_model.pkl', 'wb'))\n",
    "\n",
    "# Load the XGBoost model\n",
    "nb_model = pickle.load(open('nb_model.pkl', 'rb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "08e36c32-970a-483a-95fe-b86f1021eb31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorizer and lemmatizer saved successfully!\n"
     ]
    }
   ],
   "source": [
    "#save .pkl of vectorizer\n",
    "with open('vectorizer.pkl', 'wb') as file:\n",
    "    pickle.dump(vectorizer, file)\n",
    "\n",
    "#save .pkl of stemmer\n",
    "with open('lemmatizer.pkl', 'wb') as file:\n",
    "    pickle.dump(lemmatizer, file)\n",
    "\n",
    "print(\"Vectorizer and lemmatizer saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d2e7dc20-5f73-4594-8c7e-6127c2c56a1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The GeoSolutions technology will leverage Bene...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>$ESI on lows, down $1.50 to $2.50 BK a real po...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>For the last quarter of 2010 , Componenta 's n...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>According to the Finnish-Russian Chamber of Co...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Swedish buyout firm has sold its remaining...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5837</th>\n",
       "      <td>RISING costs have forced packaging producer Hu...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5838</th>\n",
       "      <td>Nordic Walking was first used as a summer trai...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5839</th>\n",
       "      <td>According shipping company Viking Line , the E...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5840</th>\n",
       "      <td>In the building and home improvement trade , s...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5841</th>\n",
       "      <td>HELSINKI AFX - KCI Konecranes said it has won ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5842 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Sentence Sentiment\n",
       "0     The GeoSolutions technology will leverage Bene...  positive\n",
       "1     $ESI on lows, down $1.50 to $2.50 BK a real po...  negative\n",
       "2     For the last quarter of 2010 , Componenta 's n...  positive\n",
       "3     According to the Finnish-Russian Chamber of Co...   neutral\n",
       "4     The Swedish buyout firm has sold its remaining...   neutral\n",
       "...                                                 ...       ...\n",
       "5837  RISING costs have forced packaging producer Hu...  negative\n",
       "5838  Nordic Walking was first used as a summer trai...   neutral\n",
       "5839  According shipping company Viking Line , the E...   neutral\n",
       "5840  In the building and home improvement trade , s...   neutral\n",
       "5841  HELSINKI AFX - KCI Konecranes said it has won ...  positive\n",
       "\n",
       "[5842 rows x 2 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "cb2415b3-ef13-441a-b952-125da85c6af3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RISING costs have forced packaging producer Huhtamaki to axe 90 jobs at its Hampshire manufacturing plant .'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Sentence\"].iloc[5837]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
